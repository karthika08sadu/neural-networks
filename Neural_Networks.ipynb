{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea9c2c53-30a6-43bc-b3ce-2b892fe9b972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (3.11.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras) (2.3.3)\n",
      "Requirement already satisfied: rich in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras) (0.5.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from optree->keras) (4.14.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ad85e6-d5a6-4f3f-93cc-e3c48bece491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (78.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.3.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "80f1e16c-30fa-4abf-aad7-e8e063eb6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ab74a35-428a-4127-88ac-801d3911321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5fb37276-0108-48e4-8005-637e54a881b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ecfc94-7c73-4081-a870-478dc7c80a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Alphabets_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e0ad66-f0f6-4272-9d95-da8d65990981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a986cb-92d9-4c01-8d98-21c4561a5c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a86003e3-d706-460d-956b-31f93f120ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b756e4d0-f3f0-4f93-8e75-5d8dd8e0fe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a9657ad4-9911-4746-8d59-477d7729b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e515c96-8161-4d01-bc7d-b587a07d0284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d93ef343-0d3b-486b-b5fd-623fa6cb8aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d737f4-02ef-44a8-b433-46e0fb6508b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d152b05-faf2-4a56-a6f7-7bd8692ad528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T', 'I', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'M', 'X', 'O', 'R',\n",
       "       'F', 'C', 'H', 'W', 'L', 'P', 'E', 'V', 'Y', 'Q', 'U', 'K', 'Z'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e5a75165-b4d0-49d2-9524-66a7a99f4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the target variable using label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04686475-9ed7-45a7-ac5c-bb9be6fcd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "LE=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dbfec21-b29c-42ef-92b1-ebadbdccc839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['letter']=LE.fit_transform(df['letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89575ccc-28db-4753-a2a3-fdb2f2b97a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    int64\n",
       "xbox      int64\n",
       "ybox      int64\n",
       "width     int64\n",
       "height    int64\n",
       "onpix     int64\n",
       "xbar      int64\n",
       "ybar      int64\n",
       "x2bar     int64\n",
       "y2bar     int64\n",
       "xybar     int64\n",
       "x2ybar    int64\n",
       "xy2bar    int64\n",
       "xedge     int64\n",
       "xedgey    int64\n",
       "yedge     int64\n",
       "yedgex    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d619e0-84a6-4816-85d6-f84340733af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0         2     8      3       5      1     8    13      0      6      6   \n",
       "1         5    12      3       7      2    10     5      5      4     13   \n",
       "2         4    11      6       8      6    10     6      2      6     10   \n",
       "3         7    11      6       6      3     5     9      4      6      4   \n",
       "4         2     1      3       1      1     8     6      6      6      6   \n",
       "...     ...   ...    ...     ...    ...   ...   ...    ...    ...    ...   \n",
       "19995     2     2      3       3      2     7     7      7      6      6   \n",
       "19996     7    10      8       8      4     4     8      6      9     12   \n",
       "19997     6     9      6       7      5     6    11      3      7     11   \n",
       "19998     2     3      4       2      1     8     7      2      6     10   \n",
       "19999     4     9      6       6      2     9     5      3      1      8   \n",
       "\n",
       "       x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          10       8      0       8      0       8  \n",
       "1           3       9      2       8      4      10  \n",
       "2           3       7      3       7      3       9  \n",
       "3           4      10      6      10      2       8  \n",
       "4           5       9      1       7      5      10  \n",
       "...       ...     ...    ...     ...    ...     ...  \n",
       "19995       6       4      2       8      3       7  \n",
       "19996       9      13      2       9      3       7  \n",
       "19997       9       5      2      12      2       4  \n",
       "19998       6       8      1       9      5       8  \n",
       "19999       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,1:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ff767cb1-8e41-4c13-b76e-80b4d4171ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardising the X data as mean=0 and std=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed4f1ef4-0fa7-4424-839f-e90ec675fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c836f1-e0be-4193-a955-6b9282ed63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x=SS.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16fd806c-7e09-4028-8529-c7e32ab61c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>0.291877</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-0.164704</td>\n",
       "      <td>-1.144013</td>\n",
       "      <td>0.544130</td>\n",
       "      <td>2.365097</td>\n",
       "      <td>-1.714360</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-0.917071</td>\n",
       "      <td>1.347774</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-1.305948</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>-1.438153</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510385</td>\n",
       "      <td>1.502358</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>0.719730</td>\n",
       "      <td>-0.687476</td>\n",
       "      <td>1.531305</td>\n",
       "      <td>-1.075326</td>\n",
       "      <td>0.137561</td>\n",
       "      <td>-0.495072</td>\n",
       "      <td>1.895968</td>\n",
       "      <td>-1.312807</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>0.120081</td>\n",
       "      <td>1.359441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.012309</td>\n",
       "      <td>1.199738</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>1.161947</td>\n",
       "      <td>1.138672</td>\n",
       "      <td>1.531305</td>\n",
       "      <td>-0.645273</td>\n",
       "      <td>-0.973591</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>0.690380</td>\n",
       "      <td>-1.312807</td>\n",
       "      <td>-0.446513</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>-0.269477</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.555774</td>\n",
       "      <td>1.199738</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>0.277513</td>\n",
       "      <td>-0.230939</td>\n",
       "      <td>-0.936631</td>\n",
       "      <td>0.644886</td>\n",
       "      <td>-0.232823</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-1.720796</td>\n",
       "      <td>-0.932724</td>\n",
       "      <td>0.995402</td>\n",
       "      <td>1.266419</td>\n",
       "      <td>1.074008</td>\n",
       "      <td>-0.659036</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>-1.826464</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-1.933571</td>\n",
       "      <td>-1.144013</td>\n",
       "      <td>0.544130</td>\n",
       "      <td>-0.645273</td>\n",
       "      <td>0.507945</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-0.917071</td>\n",
       "      <td>-0.552641</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>-0.877220</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>0.509640</td>\n",
       "      <td>1.359441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>-1.523844</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-1.049137</td>\n",
       "      <td>-0.687476</td>\n",
       "      <td>0.050543</td>\n",
       "      <td>-0.215220</td>\n",
       "      <td>0.878329</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-0.917071</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>-1.888428</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>-0.269477</td>\n",
       "      <td>-0.495354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1.555774</td>\n",
       "      <td>0.897117</td>\n",
       "      <td>1.428701</td>\n",
       "      <td>1.161947</td>\n",
       "      <td>0.225598</td>\n",
       "      <td>-1.430218</td>\n",
       "      <td>0.214833</td>\n",
       "      <td>0.507945</td>\n",
       "      <td>1.605094</td>\n",
       "      <td>1.494105</td>\n",
       "      <td>0.967691</td>\n",
       "      <td>2.437316</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>0.427463</td>\n",
       "      <td>-0.269477</td>\n",
       "      <td>-0.495354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1.033079</td>\n",
       "      <td>0.594497</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>0.719730</td>\n",
       "      <td>0.682135</td>\n",
       "      <td>-0.443044</td>\n",
       "      <td>1.504991</td>\n",
       "      <td>-0.603207</td>\n",
       "      <td>0.765028</td>\n",
       "      <td>1.092242</td>\n",
       "      <td>0.967691</td>\n",
       "      <td>-1.407789</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>2.367097</td>\n",
       "      <td>-0.659036</td>\n",
       "      <td>-2.350149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>-1.221224</td>\n",
       "      <td>-0.556881</td>\n",
       "      <td>-1.491354</td>\n",
       "      <td>-1.144013</td>\n",
       "      <td>0.544130</td>\n",
       "      <td>-0.215220</td>\n",
       "      <td>-0.973591</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>0.690380</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-0.877220</td>\n",
       "      <td>0.427463</td>\n",
       "      <td>0.509640</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>-0.012309</td>\n",
       "      <td>0.594497</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>0.277513</td>\n",
       "      <td>-0.687476</td>\n",
       "      <td>1.037718</td>\n",
       "      <td>-1.075326</td>\n",
       "      <td>-0.603207</td>\n",
       "      <td>-1.755172</td>\n",
       "      <td>-0.113345</td>\n",
       "      <td>-2.072973</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>-0.659036</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           xbox      ybox     width    height     onpix      xbar      ybar  \\\n",
       "0     -1.057698  0.291877 -1.053277 -0.164704 -1.144013  0.544130  2.365097   \n",
       "1      0.510385  1.502358 -1.053277  0.719730 -0.687476  1.531305 -1.075326   \n",
       "2     -0.012309  1.199738  0.435910  1.161947  1.138672  1.531305 -0.645273   \n",
       "3      1.555774  1.199738  0.435910  0.277513 -0.230939 -0.936631  0.644886   \n",
       "4     -1.057698 -1.826464 -1.053277 -1.933571 -1.144013  0.544130 -0.645273   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19995 -1.057698 -1.523844 -1.053277 -1.049137 -0.687476  0.050543 -0.215220   \n",
       "19996  1.555774  0.897117  1.428701  1.161947  0.225598 -1.430218  0.214833   \n",
       "19997  1.033079  0.594497  0.435910  0.719730  0.682135 -0.443044  1.504991   \n",
       "19998 -1.057698 -1.221224 -0.556881 -1.491354 -1.144013  0.544130 -0.215220   \n",
       "19999 -0.012309  0.594497  0.435910  0.277513 -0.687476  1.037718 -1.075326   \n",
       "\n",
       "          x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
       "0     -1.714360  0.344994 -0.917071  1.347774  0.034125 -1.305948 -0.219082   \n",
       "1      0.137561 -0.495072  1.895968 -1.312807  0.514764 -0.448492 -0.219082   \n",
       "2     -0.973591  0.344994  0.690380 -1.312807 -0.446513 -0.019764 -0.865626   \n",
       "3     -0.232823  0.344994 -1.720796 -0.932724  0.995402  1.266419  1.074008   \n",
       "4      0.507945  0.344994 -0.917071 -0.552641  0.514764 -0.877220 -0.865626   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19995  0.878329  0.344994 -0.917071 -0.172558 -1.888428 -0.448492 -0.219082   \n",
       "19996  0.507945  1.605094  1.494105  0.967691  2.437316 -0.448492  0.427463   \n",
       "19997 -0.603207  0.765028  1.092242  0.967691 -1.407789 -0.448492  2.367097   \n",
       "19998 -0.973591  0.344994  0.690380 -0.172558  0.034125 -0.877220  0.427463   \n",
       "19999 -0.603207 -1.755172 -0.113345 -2.072973  0.034125 -0.448492 -0.865626   \n",
       "\n",
       "          yedge    yedgex  \n",
       "0     -1.438153  0.122911  \n",
       "1      0.120081  1.359441  \n",
       "2     -0.269477  0.741176  \n",
       "3     -0.659036  0.122911  \n",
       "4      0.509640  1.359441  \n",
       "...         ...       ...  \n",
       "19995 -0.269477 -0.495354  \n",
       "19996 -0.269477 -0.495354  \n",
       "19997 -0.659036 -2.350149  \n",
       "19998  0.509640  0.122911  \n",
       "19999 -0.659036  0.122911  \n",
       "\n",
       "[20000 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.DataFrame(scaled_x,columns=X.columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "911c0171-a00a-4e4d-a6cd-9a9b140a768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       letter\n",
       "0          19\n",
       "1           8\n",
       "2           3\n",
       "3          13\n",
       "4           6\n",
       "...       ...\n",
       "19995       3\n",
       "19996       2\n",
       "19997      19\n",
       "19998      18\n",
       "19999       0\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.iloc[:,:1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4ebf5e5c-e22b-41d8-b174-1f477c37235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ecb8b2b1-30b8-4736-a8ed-5b0f76a141b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17133</th>\n",
       "      <td>0.510385</td>\n",
       "      <td>0.594497</td>\n",
       "      <td>1.428701</td>\n",
       "      <td>0.277513</td>\n",
       "      <td>1.138672</td>\n",
       "      <td>1.037718</td>\n",
       "      <td>0.214833</td>\n",
       "      <td>-0.232823</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>1.092242</td>\n",
       "      <td>-0.552641</td>\n",
       "      <td>-1.407789</td>\n",
       "      <td>0.408963</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>0.120081</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17646</th>\n",
       "      <td>0.510385</td>\n",
       "      <td>1.199738</td>\n",
       "      <td>-0.060486</td>\n",
       "      <td>1.161947</td>\n",
       "      <td>0.682135</td>\n",
       "      <td>-1.923805</td>\n",
       "      <td>-0.215220</td>\n",
       "      <td>0.878329</td>\n",
       "      <td>-0.915106</td>\n",
       "      <td>-0.515208</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>1.476040</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>-0.269477</td>\n",
       "      <td>1.977706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18721</th>\n",
       "      <td>1.033079</td>\n",
       "      <td>-0.010743</td>\n",
       "      <td>-0.060486</td>\n",
       "      <td>2.046381</td>\n",
       "      <td>0.225598</td>\n",
       "      <td>0.544130</td>\n",
       "      <td>-1.075326</td>\n",
       "      <td>0.137561</td>\n",
       "      <td>-0.075039</td>\n",
       "      <td>1.092242</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>-0.446513</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.427463</td>\n",
       "      <td>2.067874</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>-1.580393</td>\n",
       "      <td>-1.221224</td>\n",
       "      <td>-1.549672</td>\n",
       "      <td>-1.933571</td>\n",
       "      <td>-1.144013</td>\n",
       "      <td>-0.443044</td>\n",
       "      <td>1.935044</td>\n",
       "      <td>-0.973591</td>\n",
       "      <td>-0.915106</td>\n",
       "      <td>-0.113345</td>\n",
       "      <td>1.727857</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>1.720552</td>\n",
       "      <td>-1.438153</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>1.555774</td>\n",
       "      <td>0.897117</td>\n",
       "      <td>2.421491</td>\n",
       "      <td>1.161947</td>\n",
       "      <td>1.138672</td>\n",
       "      <td>-1.430218</td>\n",
       "      <td>0.644886</td>\n",
       "      <td>-0.973591</td>\n",
       "      <td>0.765028</td>\n",
       "      <td>0.690380</td>\n",
       "      <td>0.967691</td>\n",
       "      <td>0.995402</td>\n",
       "      <td>0.837691</td>\n",
       "      <td>-1.512171</td>\n",
       "      <td>0.120081</td>\n",
       "      <td>-1.731884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12162</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>-0.918603</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-1.491354</td>\n",
       "      <td>-0.687476</td>\n",
       "      <td>-0.443044</td>\n",
       "      <td>-0.215220</td>\n",
       "      <td>0.137561</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>0.288517</td>\n",
       "      <td>0.207525</td>\n",
       "      <td>0.995402</td>\n",
       "      <td>-0.877220</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>0.120081</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>-0.535004</td>\n",
       "      <td>-0.918603</td>\n",
       "      <td>-0.060486</td>\n",
       "      <td>0.277513</td>\n",
       "      <td>-0.230939</td>\n",
       "      <td>-0.443044</td>\n",
       "      <td>0.214833</td>\n",
       "      <td>-0.232823</td>\n",
       "      <td>-1.755172</td>\n",
       "      <td>-0.515208</td>\n",
       "      <td>0.587608</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>2.123874</td>\n",
       "      <td>1.074008</td>\n",
       "      <td>-1.438153</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13697</th>\n",
       "      <td>-0.535004</td>\n",
       "      <td>-0.918603</td>\n",
       "      <td>-0.060486</td>\n",
       "      <td>-1.049137</td>\n",
       "      <td>-0.230939</td>\n",
       "      <td>1.037718</td>\n",
       "      <td>1.504991</td>\n",
       "      <td>-0.603207</td>\n",
       "      <td>-1.335139</td>\n",
       "      <td>-1.318933</td>\n",
       "      <td>0.967691</td>\n",
       "      <td>-0.446513</td>\n",
       "      <td>1.266419</td>\n",
       "      <td>1.074008</td>\n",
       "      <td>-1.438153</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11686</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>-0.010743</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-0.164704</td>\n",
       "      <td>-0.687476</td>\n",
       "      <td>0.050543</td>\n",
       "      <td>-0.215220</td>\n",
       "      <td>-1.714360</td>\n",
       "      <td>0.765028</td>\n",
       "      <td>1.895968</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-1.305948</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>-1.048594</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18454</th>\n",
       "      <td>1.033079</td>\n",
       "      <td>0.594497</td>\n",
       "      <td>0.932305</td>\n",
       "      <td>-0.606921</td>\n",
       "      <td>-0.230939</td>\n",
       "      <td>2.518479</td>\n",
       "      <td>-2.365484</td>\n",
       "      <td>-0.603207</td>\n",
       "      <td>-1.335139</td>\n",
       "      <td>0.690380</td>\n",
       "      <td>-1.312807</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>1.266419</td>\n",
       "      <td>-2.805260</td>\n",
       "      <td>-1.048594</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           xbox      ybox     width    height     onpix      xbar      ybar  \\\n",
       "17133  0.510385  0.594497  1.428701  0.277513  1.138672  1.037718  0.214833   \n",
       "17646  0.510385  1.199738 -0.060486  1.161947  0.682135 -1.923805 -0.215220   \n",
       "18721  1.033079 -0.010743 -0.060486  2.046381  0.225598  0.544130 -1.075326   \n",
       "4584  -1.580393 -1.221224 -1.549672 -1.933571 -1.144013 -0.443044  1.935044   \n",
       "1744   1.555774  0.897117  2.421491  1.161947  1.138672 -1.430218  0.644886   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12162 -1.057698 -0.918603 -1.053277 -1.491354 -0.687476 -0.443044 -0.215220   \n",
       "1591  -0.535004 -0.918603 -0.060486  0.277513 -0.230939 -0.443044  0.214833   \n",
       "13697 -0.535004 -0.918603 -0.060486 -1.049137 -0.230939  1.037718  1.504991   \n",
       "11686 -1.057698 -0.010743 -1.053277 -0.164704 -0.687476  0.050543 -0.215220   \n",
       "18454  1.033079  0.594497  0.932305 -0.606921 -0.230939  2.518479 -2.365484   \n",
       "\n",
       "          x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
       "17133 -0.232823  0.344994  1.092242 -0.552641 -1.407789  0.408963 -0.865626   \n",
       "17646  0.878329 -0.915106 -0.515208 -0.172558  1.476040 -0.019764 -0.219082   \n",
       "18721  0.137561 -0.075039  1.092242 -0.172558 -0.446513 -0.019764  0.427463   \n",
       "4584  -0.973591 -0.915106 -0.113345  1.727857  0.034125 -0.448492  1.720552   \n",
       "1744  -0.973591  0.765028  0.690380  0.967691  0.995402  0.837691 -1.512171   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12162  0.137561  0.344994  0.288517  0.207525  0.995402 -0.877220 -0.219082   \n",
       "1591  -0.232823 -1.755172 -0.515208  0.587608  0.034125  2.123874  1.074008   \n",
       "13697 -0.603207 -1.335139 -1.318933  0.967691 -0.446513  1.266419  1.074008   \n",
       "11686 -1.714360  0.765028  1.895968 -0.172558  0.034125 -1.305948 -0.219082   \n",
       "18454 -0.603207 -1.335139  0.690380 -1.312807  0.514764  1.266419 -2.805260   \n",
       "\n",
       "          yedge    yedgex  \n",
       "17133  0.120081  0.741176  \n",
       "17646 -0.269477  1.977706  \n",
       "18721  2.067874  0.122911  \n",
       "4584  -1.438153  0.122911  \n",
       "1744   0.120081 -1.731884  \n",
       "...         ...       ...  \n",
       "12162  0.120081  0.741176  \n",
       "1591  -1.438153  0.122911  \n",
       "13697 -1.438153  0.122911  \n",
       "11686 -1.048594  0.122911  \n",
       "18454 -1.048594  0.741176  \n",
       "\n",
       "[14000 rows x 16 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "393d8db1-4f46-45ff-9f67-6be8ffe3e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 16)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "18a3e664-8ff7-4463-ae68-b59c257d2dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8f04503c-205c-4615-9b69-544b504b364c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y['letter'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e5229033-db20-4cec-9c57-e962083c8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Build a Simple ANN Model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(y['letter'].unique()), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "06025f7e-fca3-4263-a1cf-b1fab920f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# adam learning rate is 0.001 default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3a07d7f1-2c75-4269-b4a1-569da1980d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5691 - loss: 1.6345 - val_accuracy: 0.7300 - val_loss: 0.9372\n",
      "Epoch 2/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7766 - loss: 0.7701 - val_accuracy: 0.8079 - val_loss: 0.6725\n",
      "Epoch 3/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.5892 - val_accuracy: 0.8400 - val_loss: 0.5395\n",
      "Epoch 4/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8558 - loss: 0.4825 - val_accuracy: 0.8657 - val_loss: 0.4546\n",
      "Epoch 5/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.4102 - val_accuracy: 0.8811 - val_loss: 0.4011\n",
      "Epoch 6/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8948 - loss: 0.3571 - val_accuracy: 0.8854 - val_loss: 0.3766\n",
      "Epoch 7/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.3166 - val_accuracy: 0.9011 - val_loss: 0.3351\n",
      "Epoch 8/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9149 - loss: 0.2819 - val_accuracy: 0.9071 - val_loss: 0.3017\n",
      "Epoch 9/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.2548 - val_accuracy: 0.9154 - val_loss: 0.2795\n",
      "Epoch 10/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.2327 - val_accuracy: 0.9196 - val_loss: 0.2655\n",
      "Epoch 11/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.2129 - val_accuracy: 0.9182 - val_loss: 0.2562\n",
      "Epoch 12/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9432 - loss: 0.1934 - val_accuracy: 0.9261 - val_loss: 0.2515\n",
      "Epoch 13/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.1793 - val_accuracy: 0.9275 - val_loss: 0.2275\n",
      "Epoch 14/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9521 - loss: 0.1642 - val_accuracy: 0.9261 - val_loss: 0.2235\n",
      "Epoch 15/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9524 - loss: 0.1556 - val_accuracy: 0.9296 - val_loss: 0.2221\n",
      "Epoch 16/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.1451 - val_accuracy: 0.9300 - val_loss: 0.2155\n",
      "Epoch 17/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.1318 - val_accuracy: 0.9379 - val_loss: 0.1983\n",
      "Epoch 18/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9650 - loss: 0.1224 - val_accuracy: 0.9314 - val_loss: 0.2124\n",
      "Epoch 19/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.1153 - val_accuracy: 0.9421 - val_loss: 0.1920\n",
      "Epoch 20/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9695 - loss: 0.1060 - val_accuracy: 0.9382 - val_loss: 0.1862\n",
      "Epoch 21/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9704 - loss: 0.1017 - val_accuracy: 0.9400 - val_loss: 0.1900\n",
      "Epoch 22/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.0972 - val_accuracy: 0.9400 - val_loss: 0.1774\n",
      "Epoch 23/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0882 - val_accuracy: 0.9436 - val_loss: 0.1802\n",
      "Epoch 24/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9760 - loss: 0.0849 - val_accuracy: 0.9404 - val_loss: 0.1930\n",
      "Epoch 25/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0760 - val_accuracy: 0.9439 - val_loss: 0.1789\n",
      "Epoch 26/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0755 - val_accuracy: 0.9411 - val_loss: 0.1750\n",
      "Epoch 27/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.0701 - val_accuracy: 0.9443 - val_loss: 0.1705\n",
      "Epoch 28/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0630 - val_accuracy: 0.9461 - val_loss: 0.1700\n",
      "Epoch 29/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0597 - val_accuracy: 0.9436 - val_loss: 0.1720\n",
      "Epoch 30/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.0560 - val_accuracy: 0.9454 - val_loss: 0.1755\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "954d2757-94c8-4864-8105-046c00c376b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b77951e690>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "031dc875-710a-4e6b-bd9b-0620a973807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0789\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "da89547c-66c4-4abc-ae33-998fa16442d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c4564-74b4-4fd2-aba9-2be33489b5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1a2e245-2dec-4910-8693-5fc7d23b4576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.1166639328003\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the Model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy:\", acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5105be64-2989-4a98-a5fe-185a6d0975a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7bea676-32bf-44fc-96a7-878aa7e4a6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  2, 10, ..., 20,  1, 20], shape=(6000,))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b42dbc20-ec57-4833-9c92-c56732a92eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9411666666666667\n",
      "0.9424641636310972\n",
      "0.9409447483014526\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred,average='macro'))\n",
    "print(recall_score(y_test,y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d7a0d5c7-d631-4edc-b2f7-781cf3abe503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9831    0.9749       237\n",
      "           1     0.8875    0.9261    0.9064       230\n",
      "           2     0.9856    0.9276    0.9557       221\n",
      "           3     0.9451    0.9256    0.9353       242\n",
      "           4     0.9286    0.9043    0.9163       230\n",
      "           5     0.9307    0.9267    0.9287       232\n",
      "           6     0.9668    0.8793    0.9210       232\n",
      "           7     0.8793    0.9273    0.9027       220\n",
      "           8     0.8840    0.9779    0.9286       226\n",
      "           9     0.9949    0.8750    0.9311       224\n",
      "          10     0.9355    0.9144    0.9248       222\n",
      "          11     0.9524    0.9649    0.9586       228\n",
      "          12     0.9617    0.9496    0.9556       238\n",
      "          13     0.9454    0.9574    0.9514       235\n",
      "          14     0.9500    0.9248    0.9372       226\n",
      "          15     0.9662    0.9502    0.9582       241\n",
      "          16     0.9130    0.9830    0.9467       235\n",
      "          17     0.8838    0.9383    0.9103       227\n",
      "          18     0.9277    0.9732    0.9499       224\n",
      "          19     0.9828    0.9540    0.9682       239\n",
      "          20     0.9630    0.9590    0.9610       244\n",
      "          21     0.9683    0.9345    0.9511       229\n",
      "          22     0.9333    0.9912    0.9614       226\n",
      "          23     0.9685    0.9110    0.9389       236\n",
      "          24     0.9023    0.9788    0.9390       236\n",
      "          25     0.9808    0.9273    0.9533       220\n",
      "\n",
      "    accuracy                         0.9412      6000\n",
      "   macro avg     0.9425    0.9409    0.9410      6000\n",
      "weighted avg     0.9427    0.9412    0.9412      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred,digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "32af0952-b9a4-468a-b725-d11f64e6b927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[233   1   0   0   0   0   0   0   0   0   0   1   1   0   0   0   0   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0 213   0   0   0   0   0   4   0   0   1   0   0   0   0   0   0   3\n",
      "    6   0   0   3   0   0   0   0]\n",
      " [  0   0 205   0   4   0   1   1   3   0   0   1   0   0   2   0   0   1\n",
      "    0   0   2   0   1   0   0   0]\n",
      " [  0   2   0 224   0   0   1   1   1   0   1   0   0   6   1   0   1   2\n",
      "    0   0   2   0   0   0   0   0]\n",
      " [  0   5   0   0 208   5   1   0   0   0   0   4   1   0   0   0   1   0\n",
      "    2   0   0   0   0   2   0   1]\n",
      " [  0   1   0   1   1 215   0   0   1   0   0   0   0   0   0   5   0   0\n",
      "    2   2   0   0   0   1   3   0]\n",
      " [  0   1   0   0   3   0 204   2   0   0   1   3   1   1   4   0   7   2\n",
      "    0   0   1   2   0   0   0   0]\n",
      " [  0   5   0   1   1   0   0 204   0   0   1   1   1   0   0   0   0   5\n",
      "    0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 221   0   0   0   0   0   0   1   1   0\n",
      "    0   0   0   0   0   0   1   1]\n",
      " [  0   0   0   0   0   3   0   0  22 196   0   0   0   1   1   0   0   0\n",
      "    1   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0  10   0   0 203   0   1   0   0   0   0   5\n",
      "    0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   1   0   0   0 220   0   0   0   0   0   1\n",
      "    2   0   0   0   0   2   0   1]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0 226   2   1   0   0   0\n",
      "    0   0   0   0   7   0   0   0]\n",
      " [  0   1   0   0   0   0   0   1   0   0   1   0   1 225   0   0   0   5\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  1   0   2   3   0   0   0   1   0   0   0   0   1   0 209   0   5   2\n",
      "    0   0   0   0   2   0   0   0]\n",
      " [  0   1   0   0   1   6   0   1   0   0   0   1   0   0   0 229   1   0\n",
      "    0   0   0   0   0   0   1   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   2   1 231   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   3   0   2   0   0   1   2   0   0   2   0   0   1   0   0   3 213\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   1   0   1   0   0   1   0   0   0   0   0   0   0   0\n",
      "  218   0   0   0   0   0   2   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0 228   0   0   0   1   8   0]\n",
      " [  0   0   1   0   0   0   0   1   0   0   1   0   1   2   0   0   0   0\n",
      "    0   0 234   0   3   0   1   0]\n",
      " [  0   4   0   0   0   1   1   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0 214   2   0   6   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "    0   0   0   1 224   0   0   0]\n",
      " [  0   3   0   4   1   0   0   2   0   0   5   0   0   0   0   0   0   0\n",
      "    1   1   0   0   0 215   3   1]\n",
      " [  1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   2   0   0   1 231   0]\n",
      " [  3   0   0   0   3   0   0   0   2   0   0   0   0   0   0   0   3   1\n",
      "    3   1   0   0   0   0   0 204]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184325e-62b7-4137-939d-69ba9c65a06c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Manual Grid Search\n",
    "import itertools\n",
    "#### Function to create ANN model\n",
    "def create_model(neurons1=128, neurons2=64, activation='relu', learning_rate=0.001, dropout_rate=0.1):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(neurons1, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(neurons2, activation=activation))\n",
    "    \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(len(y.iloc[:,0].unique()), activation='softmax'))  # softmax for multi-class classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#### Hyperparameter options\n",
    "\n",
    "neurons1_list = [64, 128]\n",
    "\n",
    "neurons2_list = [32, 64]\n",
    "\n",
    "activation_list = ['relu', 'tanh']\n",
    "\n",
    "learning_rate_list = [0.001, 0.01]\n",
    "\n",
    "dropout_list = [0.1, 0.2]\n",
    "\n",
    "#### Store results\n",
    "results = []\n",
    "\n",
    "#### Manual grid search\n",
    "\n",
    "for neurons1, neurons2, activation, lr, dropout_rate in itertools.product(\n",
    "        neurons1_list, neurons2_list, activation_list, learning_rate_list, dropout_list\n",
    "):\n",
    "   \n",
    "    print(f\"Training with neurons1={neurons1}, neurons2={neurons2}, activation={activation}, lr={lr}, dropout={dropout_rate}\")\n",
    "    \n",
    "    model = create_model(neurons1, neurons2, activation, lr, dropout_rate)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "    \n",
    "    results.append((neurons1, neurons2, activation, lr, dropout_rate, val_acc))\n",
    "    \n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "#### Find best hyperparameters\n",
    "best_params = max(results, key=lambda x: x[5])\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "\n",
    "print(f\"neurons1={best_params[0]}, neurons2={best_params[1]}, activation=\n",
    "{best_params[2]}, learning_rate={best_params[3]}, dropout_rate={best_params[4]}\")\n",
    "\n",
    "print(f\"Best Validation Accuracy: {best_params[5]:.4f}\")\n",
    "\n",
    "#### Train final model with best hyperparameters\n",
    "\n",
    "final_model = create_model(best_params[0], best_params[1], best_params[2], \n",
    "\n",
    "best_params[3], best_params[4])\n",
    "\n",
    "final_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "#### Evaluate on test set\n",
    "loss, accuracy = final_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b058349-802c-41bf-9819-b066ad067c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from scikeras) (3.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from scikeras) (1.7.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.2.0->scikeras) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.2.0->scikeras) (2.3.3)\n",
      "Requirement already satisfied: rich in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.2.0->scikeras) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.2.0->scikeras) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.2.0->scikeras) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.2.0->scikeras) (0.5.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.2.0->scikeras) (24.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from optree->keras>=3.2.0->scikeras) (4.14.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.2.0->scikeras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sivap\\appdata\\roaming\\python\\python313\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e27a810b-9f54-458e-809b-aed8507cfd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'model__activation': 'relu', 'model__dropout_rate': 0.1, 'model__learning_rate': 0.001, 'model__neurons1': 128, 'model__neurons2': 64}\n",
      "Best Cross-Validation Accuracy: 0.9476\n",
      "Test Accuracy: 0.9575\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to create ANN model\n",
    "def create_model(neurons1=128, neurons2=64, activation='relu', learning_rate=0.001, dropout_rate=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons1, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap model with KerasClassifier\n",
    "clf = KerasClassifier(model=create_model, verbose=0, epochs=50, batch_size=32)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"model__neurons1\": [64, 128],\n",
    "    \"model__neurons2\": [32, 64],\n",
    "    \"model__activation\": ['relu', 'tanh'],\n",
    "    \"model__learning_rate\": [0.001, 0.01],\n",
    "    \"model__dropout_rate\": [0.1, 0.2]\n",
    "}\n",
    "# Grid search\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv=3, n_jobs=-1, scoring=\"accuracy\")\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best params\n",
    "print(\"Best Hyperparameters:\", grid_result.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy: {:.4f}\".format(grid_result.best_score_))\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = grid_result.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy: {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "08bd2312-248e-40ad-9791-c42df624e02c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4848 - loss: 1.8140 - val_accuracy: 0.7150 - val_loss: 1.0265\n",
      "Epoch 2/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7024 - loss: 0.9851 - val_accuracy: 0.7889 - val_loss: 0.7494\n",
      "Epoch 3/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7577 - loss: 0.7858 - val_accuracy: 0.8164 - val_loss: 0.6197\n",
      "Epoch 4/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.6914 - val_accuracy: 0.8396 - val_loss: 0.5346\n",
      "Epoch 5/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.6121 - val_accuracy: 0.8532 - val_loss: 0.4831\n",
      "Epoch 6/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.5508 - val_accuracy: 0.8743 - val_loss: 0.4279\n",
      "Epoch 7/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8424 - loss: 0.5040 - val_accuracy: 0.8804 - val_loss: 0.3951\n",
      "Epoch 8/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8501 - loss: 0.4738 - val_accuracy: 0.8879 - val_loss: 0.3745\n",
      "Epoch 9/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.4347 - val_accuracy: 0.8986 - val_loss: 0.3369\n",
      "Epoch 10/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8636 - loss: 0.4212 - val_accuracy: 0.9007 - val_loss: 0.3264\n",
      "Epoch 11/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8755 - loss: 0.3844 - val_accuracy: 0.9068 - val_loss: 0.3034\n",
      "Epoch 12/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.3626 - val_accuracy: 0.9104 - val_loss: 0.2901\n",
      "Epoch 13/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.3595 - val_accuracy: 0.9104 - val_loss: 0.2740\n",
      "Epoch 14/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.3328 - val_accuracy: 0.9179 - val_loss: 0.2647\n",
      "Epoch 15/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8932 - loss: 0.3135 - val_accuracy: 0.9175 - val_loss: 0.2496\n",
      "Epoch 16/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8948 - loss: 0.3171 - val_accuracy: 0.9261 - val_loss: 0.2385\n",
      "Epoch 17/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9035 - loss: 0.2942 - val_accuracy: 0.9264 - val_loss: 0.2339\n",
      "Epoch 18/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.2811 - val_accuracy: 0.9264 - val_loss: 0.2197\n",
      "Epoch 19/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9107 - loss: 0.2801 - val_accuracy: 0.9311 - val_loss: 0.2236\n",
      "Epoch 20/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.2631 - val_accuracy: 0.9254 - val_loss: 0.2163\n",
      "Epoch 21/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2588 - val_accuracy: 0.9343 - val_loss: 0.2042\n",
      "Epoch 22/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.2569 - val_accuracy: 0.9318 - val_loss: 0.2024\n",
      "Epoch 23/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9171 - loss: 0.2456 - val_accuracy: 0.9371 - val_loss: 0.1936\n",
      "Epoch 24/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2369 - val_accuracy: 0.9379 - val_loss: 0.1866\n",
      "Epoch 25/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.2300 - val_accuracy: 0.9400 - val_loss: 0.1889\n",
      "Epoch 26/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.2226 - val_accuracy: 0.9393 - val_loss: 0.1817\n",
      "Epoch 27/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9303 - loss: 0.2144 - val_accuracy: 0.9400 - val_loss: 0.1802\n",
      "Epoch 28/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.2113 - val_accuracy: 0.9429 - val_loss: 0.1739\n",
      "Epoch 29/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.2043 - val_accuracy: 0.9432 - val_loss: 0.1743\n",
      "Epoch 30/30\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9329 - loss: 0.2009 - val_accuracy: 0.9461 - val_loss: 0.1652\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Build a best ANN Model\n",
    "Tuned_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(len(y['letter'].unique()), activation='softmax')\n",
    "])\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "Tuned_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# adam learning rate is 0.001 default\n",
    "history = Tuned_model.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a02ccaf6-d242-45d0-a244-92b2ef0267d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_tune=Tuned_model.predict(X_test)\n",
    "y_pred_tune = np.argmax(y_pred_tune, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0a10aaa7-9907-45e8-ad7d-0e216b100d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  2, 10, ..., 20,  1, 20], shape=(6000,))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ff7cd648-fd2a-4ba6-a865-227d2e7768ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9453333333333334\n",
      "0.9458561736561522\n",
      "0.9452830679205502\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred_tune))\n",
    "print(precision_score(y_test,y_pred_tune,average='macro'))\n",
    "print(recall_score(y_test,y_pred_tune,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5ad11-5571-406e-9c78-e4da123eca56",
   "metadata": {},
   "source": [
    "From the hyper pearameter tuning we get the best values as\n",
    "\n",
    "Best Hyperparameters:\n",
    "\n",
    "neurons1=128, neurons2=64, activation=relu, learning_rate=0.001, dropout_rate=0.1\n",
    "Best Validation Accuracy: 0.9453"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c487840-b7c8-4c95-9e30-c5d225481a59",
   "metadata": {},
   "source": [
    "* The default ANN achieved ~94.1% validation accuracy, showing strong baseline performance.\n",
    "* After hyperparameter tuning with GridSearchCV, the best model achieved ~94.6% validation accuracy.\n",
    "* The tuned model used 128–64 neurons with relu activation, dropout of 0.1, and a learning rate of 0.001.\n",
    "* Compared to the baseline, tuning improved validation accuracy by ~0.5% and reduced validation loss, showing better generalization.\n",
    "* This demonstrates that hyperparameter tuning can significantly improve model performance by optimizing the network’s structure and learning behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482be2de-e7ef-4cb2-a063-820499d1fa3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
